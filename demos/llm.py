import json
import os
import re
from tqdm import tqdm
from openai import OpenAI
from typing import List, Dict

class SparkAPIClient:
    def __init__(self, api_key: str, base_url: str = "https://spark-api-open.xf-yun.com/v1"):
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        self.model = "lite"

    def create_completion(self, messages: List[Dict]) -> Dict:
        """åˆ›å»ºå¸¦æ ¼å¼æ ¡éªŒçš„APIè¯·æ±‚"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.3,
                max_tokens=1500,
                response_format={"type": "json_object"}
            )
            
            content = response.choices[0].message.content
            cleaned_content = self._clean_response(content)  # æ¸…ç†æ ‡è®°
            if not self._validate_response(cleaned_content):
                raise ValueError("å“åº”æ ¼å¼éªŒè¯å¤±è´¥")
                
            return {
                "status": "success",
                "content": json.loads(cleaned_content),
                "raw_response": content  # ä¿ç•™åŸå§‹å“åº”ä»¥ä¾¿è°ƒè¯•
            }
        except Exception as e:
            return {
                "status": "error",
                "message": str(e),
                "raw_response": content if 'content' in locals() else None
            }

    def _clean_response(self, content: str) -> str:
        """æ¸…ç†å“åº”ä¸­çš„ ```json å’Œ ``` æ ‡è®°"""
        content = content.strip()
        if content.startswith("```json"):
            content = content[7:]  # ç§»é™¤ ```json
        if content.endswith("```"):
            content = content[:-3]  # ç§»é™¤ ```
        return content.strip()

    def _validate_response(self, content: str) -> bool:
        """éªŒè¯å“åº”æ˜¯å¦åŒ…å«å¿…è¦å­—æ®µ"""
        try:
            data = json.loads(content)
            # æ ¹æ®ä½ æœŸæœ›çš„æ ¼å¼è°ƒæ•´å¿…è¦å­—æ®µ
            return all(key in data for key in ["vulnerability_type", "severity", "description", "recommendations"])
        except:
            return False

def process_prompts(prompts_file: str, output_file: str, api_key: str):
    """å¤„ç†æ‰€æœ‰promptså¹¶ç”Ÿæˆåˆå¹¶æŠ¥å‘Š"""
    spark_client = SparkAPIClient(api_key=api_key)
    consolidated = []

    try:
        with open(prompts_file, "r", encoding="utf-8") as f:
            prompts = json.load(f)

        valid_count = 0
        with tqdm(total=len(prompts), desc="åˆ†æè¿›åº¦", unit="ä¸ª") as pbar:
            for idx, prompt_pair in enumerate(prompts, 1):
                if not validate_prompt_format(prompt_pair):
                    print(f"\nè·³è¿‡æ— æ•ˆprompt #{idx}")
                    pbar.update(1)
                    continue
                
                # æ„é€ è¯·æ±‚æ¶ˆæ¯
                messages = [
                    {
                        "role": "system",
                        "content": f"{prompt_pair[0]['content']}\nè¯·ä¸¥æ ¼ä½¿ç”¨JSONæ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼švulnerability_type, severity, description, recommendations"
                    },
                    {
                        "role": "user",
                        "content": json.dumps({
                            "file_info": prompt_pair[1]["content"]["file_path"],
                            "vulnerabilities": [
                                f"{v['test_id']}-{v['line_number']}" 
                                for v in prompt_pair[1]["content"]["vulnerabilities"]
                            ],
                            "code_snippets": prompt_pair[1]["content"]["code_context"]
                        }, ensure_ascii=False)
                    }
                ]
                
                # è°ƒç”¨API
                response = spark_client.create_completion(messages)
                
                # è®°å½•ç»“æœ
                consolidated.append({
                    "file_path": prompt_pair[1]["content"]["file_path"],
                    "vulnerabilities": prompt_pair[1]["content"]["vulnerabilities"],
                    "analysis": response
                })
                valid_count += 1
                pbar.update(1)

        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump({
                "statistics": {
                    "total_prompts": len(prompts),
                    "valid_prompts": valid_count,
                    "success_rate": f"{(valid_count/len(prompts))*100:.1f}%"
                },
                "results": consolidated
            }, f, indent=2, ensure_ascii=False)

        print(f"\nâœ… æˆåŠŸå¤„ç† {valid_count}/{len(prompts)} ä¸ªprompt")
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜è‡³ï¼š{os.path.abspath(output_file)}")

    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥ï¼š{str(e)}")

def validate_prompt_format(prompt_pair: List) -> bool:
    """å¢å¼ºçš„promptæ ¼å¼éªŒè¯"""
    try:
        # åŸºç¡€ç»“æ„éªŒè¯
        if not isinstance(prompt_pair, list) or len(prompt_pair) != 2:
            return False
        
        # è§’è‰²éªŒè¯
        if prompt_pair[0].get("role") != "system" or prompt_pair[1].get("role") != "user":
            return False
        
        # å†…å®¹ç»“æ„éªŒè¯
        user_content = prompt_pair[1].get("content", {})
        if not isinstance(user_content, dict):
            return False
        
        # å¿…è¦å­—æ®µéªŒè¯
        required_fields = ["file_path", "vulnerabilities", "code_context"]
        if not all(field in user_content for field in required_fields):
            return False
        
        # æ¼æ´æ¡ç›®éªŒè¯
        for vuln in user_content["vulnerabilities"]:
            if not isinstance(vuln, dict) or "line_number" not in vuln:
                return False
        
        return True

    except (KeyError, TypeError):
        return False

if __name__ == "__main__":
    # é…ç½®å‚æ•°
    CONFIG = {
        "prompts_file": r"F:\qqprofile\BAVEL\py150_files\security_report\prompt_report\file_based_prompts.json",
        "output_file": r"F:\qqprofile\BAVEL\py150_files\security_report\llm_report\consolidated_report.json",
        "api_key": "kIMgPrepVzGlpgTpGZua:lmpNuZUmvnIzhqbERzho"
    }
    
    process_prompts(**CONFIG)